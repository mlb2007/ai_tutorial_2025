{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from json import JSONDecodeError\n",
    "\n",
    "# Now create an interactive Plotly bar chart\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables\n",
    "API_KEY = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://support.qs.com/hc/en-gb/articles/4410488025106-QS-World-University-Rankings-by-Subject\n",
    "### The rankings columns are:\n",
    "* Academic Reputation (30% weight)\n",
    "-- The Academic Reputation (AR) indicator measures the reputation of institutions and their programmes by asking academic experts to nominate universities based on their subject area of expertise. Pioneered by QS in 2004, it asks the question: which universities are demonstrating academic excellence? To answer this we collect and distil the collective intelligence of academics from around the world via our Academic Survey, evaluating nominations for approximately 7000 institutions each year.The indicator not only illuminates the quality of an institution's research, but also their approach to academic partnerships, their strategic impact, their educational innovativeness and the impact they have made on education and society at large.\n",
    "The indicator is the centrepiece of almost all of the rankings across the QS portfolio. \n",
    "\n",
    "* Employer Reputation (15% weight)\n",
    "-- The Employer Reputation (ER) indicator measures the reputation of institutions and their programmes among employers. We remain the only major ranking to focus on this vital aspect of a student's educational journey.\n",
    "\n",
    "* Citations per Paper\n",
    "-- The Citations per Paper (CPP) indicator measures the impact and quality of the scientific work done by institutions, on average per publication.\n",
    "\n",
    "* H-Index\n",
    "-- The h-index is an index that attempts to measure both the productivity and impact of the published work of a scientist or scholar. The index is based on the set of the scientistâ€™s most cited papers and the number of citations that they have received in other publications. It can also be applied to the productivity and impact of a group of scientists, such as a department, or an institution (as in the case of our indicator), or a country, as well as a scholarly journal. The index is defined as the maximum value of h such that the given entity (author, journal, department, institution, etc.) has published at least h papers that have each been cited at least h times (https://doi.org/10.1073/pnas.0507655102). We use institution-level H Index.\n",
    "\n",
    "* International Research Network\n",
    "-- International Research Network (IRN) is a measure of an institution's success in creating and sustaining research partnerships with institutions in other locations. The indicator measures how diverse and rich an institution's research network is by looking at the number of different countries represented, and whether these relationships are renewed and repeated. We only consider sustained partnerships, defined as those which result in three or more joint papers published in a five-year period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_us_institutions_for_life_sciences(num_institutions=200):\n",
    "    file_path = '2025_QS_rankings.xlsx'\n",
    "    # Reload with correct settings: skip to row 10 (0-based), treat row 10 as header\n",
    "    df_qs = pd.read_excel(file_path, sheet_name=\"Life Sciences & Medicine\", skiprows=10, header=0)\n",
    "\n",
    "    # Drop rows with missing Institution (bottom padding, if any)\n",
    "    df_qs = df_qs.dropna(subset=[\"Institution\"])\n",
    "\n",
    "    # Select top 100 programs\n",
    "    df_top = df_qs.head(num_institutions)\n",
    "\n",
    "    # Select relevant columns\n",
    "    df_top = df_top[[\n",
    "        \"2025\", \"Institution\", \"Country / Territory\", \"Score\", \"Academic\", \"Employer\", \"Citations\", \"H\", \"IRN\"\n",
    "    ]]\n",
    "\n",
    "    # Rename 2025 column to \"Rank\" for clarity\n",
    "    df_top = df_top.rename(columns={\"2025\": \"Rank\"})\n",
    "    # Clean up the rank column that has = sign prefixed and make it an integer\n",
    "    df_top['Rank'] = df_top['Rank'].str.replace('=', '')\n",
    "    df_top['Rank'] = df_top['Rank'].astype(int)\n",
    "\n",
    "    # rank the institutions by overall Rank and H-index (higher the H-index, better the institution)\n",
    "    df_top = df_top.sort_values(by=['Rank', 'H'], ascending=True)\n",
    "\n",
    "    # consider only US instituions and rank by H-index (higher the H-index, better the institution) and drop the country column\n",
    "    df_top_us = df_top[df_top['Country / Territory'] == 'United States of America']\n",
    "    df_top_us = df_top_us.drop(columns=['Country / Territory'])\n",
    "    print(df_top_us.head(10))\n",
    "\n",
    "    # clean up the institution names\n",
    "    list_of_institutions = df_top_us['Institution'].values.tolist()\n",
    "    cleaned_institutions = []\n",
    "    for institution in list_of_institutions:\n",
    "        cleaned = re.sub(r'\\([^)]*\\)', '', institution)\n",
    "        cleaned = cleaned.replace(',', '-')\n",
    "        cleaned = cleaned.strip()\n",
    "        cleaned_institutions.append(cleaned)\n",
    "\n",
    "    # no space before and after '-' within the string if there are space\n",
    "    cleaned_institutions = [re.sub(r'\\s*-\\s*', '-', institution) for institution in cleaned_institutions]\n",
    "\n",
    "    # remove any duplicates\n",
    "    cleaned_institutions = list(dict.fromkeys(cleaned_institutions))\n",
    "\n",
    "    # remove any empty strings\n",
    "    cleaned_institutions = [institution for institution in cleaned_institutions if institution]\n",
    "\n",
    "    return cleaned_institutions, df_top_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_top_100_us_institutions_for_life_sciences():\n",
    "    top_institutions, df_top100_us = get_top_us_institutions_for_life_sciences(100)\n",
    "    print(top_institutions)\n",
    "\n",
    "test_top_100_us_institutions_for_life_sciences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_admission_data(school_name):\n",
    "    print(f\"Getting admission data for {school_name}\")\n",
    "    base_url = \"https://api.data.gov/ed/collegescorecard/v1/schools\"\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"school.name\": school_name,\n",
    "        \"fields\": \"school.name,latest.admissions.admission_rate.overall,latest.student.demographics.race_ethnicity.asian,latest.student.demographics.race_ethnicity.white,latest.student.demographics.race_ethnicity.hispanic,latest.student.demographics.race_ethnicity.black\",\n",
    "        \"per_page\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    try:\n",
    "        data = response.json()\n",
    "        # Convert to pandas dataframe\n",
    "        df = pd.json_normalize(data['results'])\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"Error getting admission data for {school_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # if df is all NAN, return empty dataframe\n",
    "    if df.isna().all().all():\n",
    "        print(f\"No admission data found for {school_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # check if everything is NaN except the school name column and if so, return empty dataframe \n",
    "    # get all columns except the school name column\n",
    "    columns_to_check = df.columns.tolist()\n",
    "    columns_to_check.remove('school.name')\n",
    "    if df[columns_to_check].isna().all().all():\n",
    "        print(f\"No admission data found for {school_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_institutions, df_top_us = get_top_us_institutions_for_life_sciences()\n",
    "\n",
    "aggregated_df = pd.DataFrame()\n",
    "for institution in top_institutions:\n",
    "    df_admission_data = get_school_admission_data(institution)\n",
    "    if not df_admission_data.empty:\n",
    "        # Initialize aggregated_df with the first non-empty dataframe\n",
    "        if aggregated_df.empty:\n",
    "            aggregated_df = df_admission_data\n",
    "        else:\n",
    "            if not df_admission_data.isna().all().all():\n",
    "                aggregated_df = pd.concat([aggregated_df, df_admission_data], ignore_index=True)\n",
    "\n",
    "aggregated_df.head()\n",
    "\n",
    "# write aggregated_df to csv\n",
    "aggregated_df.to_csv(\"top_us_institutions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proxy_data = pd.read_csv(\"proxy_data.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df_proxy_data.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df_proxy_data.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge df_proxy_data on 'institution' and aggregate_df on 'school.name'\n",
    "df_merged = pd.merge(df_proxy_data, aggregated_df, left_on='institution', right_on='school.name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.to_csv(\"college_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logic for estimating public vs. private school %\n",
    "# Heuristic logic based on socioeconomic proxies:\n",
    "# - Higher Pell Grant % â†’ likely more public school\n",
    "# - Higher in-state % â†’ likely more public school\n",
    "# - Higher parent income â†’ likely more private school\n",
    "# We'll combine these heuristics linearly.\n",
    "\n",
    "# Normalize relevant columns\n",
    "df['pct_pell_norm'] = df['pct_pell'] / 100\n",
    "df['in_state_ug_pct_norm'] = df['in_state_ug_pct'] / 100\n",
    "df['par_mean_norm'] = (df['par_mean'] - df['par_mean'].min()) / (df['par_mean'].max() - df['par_mean'].min())\n",
    "\n",
    "# Define weights for the heuristic (you can tweak this based on literature / assumptions)\n",
    "w_pell = 0.4\n",
    "w_in_state = 0.4\n",
    "w_income = 0.2\n",
    "\n",
    "# Estimate \"Public school % score\"\n",
    "df['public_school_score'] = (\n",
    "    w_pell * df['pct_pell_norm'] +\n",
    "    w_in_state * df['in_state_ug_pct_norm'] +\n",
    "    w_income * (1 - df['par_mean_norm'])  # higher income â†’ less public\n",
    ")\n",
    "\n",
    "# Clip scores between 0 and 1\n",
    "df['public_school_pct'] = (df['public_school_score']).clip(0, 1)\n",
    "\n",
    "# Private school % is complementary\n",
    "df['private_school_pct'] = 1 - df['public_school_pct']\n",
    "\n",
    "# Prepare data for plot\n",
    "plot_df = df[['institution', 'public_school_pct', 'private_school_pct']].dropna().sort_values(by='public_school_pct', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Public School %', x=plot_df['institution'], y=plot_df['public_school_pct'] * 100),\n",
    "    go.Bar(name='Private School %', x=plot_df['institution'], y=plot_df['private_school_pct'] * 100)\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Estimated % of Students from Public vs Private Schools',\n",
    "    xaxis_title='Institution',\n",
    "    yaxis_title='Percentage of Students',\n",
    "    xaxis_tickangle=-45,\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
