{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from json import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables\n",
    "API_KEY = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://support.qs.com/hc/en-gb/articles/4410488025106-QS-World-University-Rankings-by-Subject\n",
    "### The rankings columns are:\n",
    "* Academic Reputation (30% weight)\n",
    "-- The Academic Reputation (AR) indicator measures the reputation of institutions and their programmes by asking academic experts to nominate universities based on their subject area of expertise. Pioneered by QS in 2004, it asks the question: which universities are demonstrating academic excellence? To answer this we collect and distil the collective intelligence of academics from around the world via our Academic Survey, evaluating nominations for approximately 7000 institutions each year.The indicator not only illuminates the quality of an institution's research, but also their approach to academic partnerships, their strategic impact, their educational innovativeness and the impact they have made on education and society at large.\n",
    "The indicator is the centrepiece of almost all of the rankings across the QS portfolio. \n",
    "\n",
    "* Employer Reputation (15% weight)\n",
    "-- The Employer Reputation (ER) indicator measures the reputation of institutions and their programmes among employers. We remain the only major ranking to focus on this vital aspect of a student's educational journey.\n",
    "\n",
    "* Citations per Paper\n",
    "-- The Citations per Paper (CPP) indicator measures the impact and quality of the scientific work done by institutions, on average per publication.\n",
    "\n",
    "* H-Index\n",
    "-- The h-index is an index that attempts to measure both the productivity and impact of the published work of a scientist or scholar. The index is based on the set of the scientist’s most cited papers and the number of citations that they have received in other publications. It can also be applied to the productivity and impact of a group of scientists, such as a department, or an institution (as in the case of our indicator), or a country, as well as a scholarly journal. The index is defined as the maximum value of h such that the given entity (author, journal, department, institution, etc.) has published at least h papers that have each been cited at least h times (https://doi.org/10.1073/pnas.0507655102). We use institution-level H Index.\n",
    "\n",
    "* International Research Network\n",
    "-- International Research Network (IRN) is a measure of an institution's success in creating and sustaining research partnerships with institutions in other locations. The indicator measures how diverse and rich an institution's research network is by looking at the number of different countries represented, and whether these relationships are renewed and repeated. We only consider sustained partnerships, defined as those which result in three or more joint papers published in a five-year period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_100_us_institutions_for_life_sciences():\n",
    "    file_path = '2025_QS_rankings.xlsx'\n",
    "    # Reload with correct settings: skip to row 10 (0-based), treat row 10 as header\n",
    "    df_qs = pd.read_excel(file_path, sheet_name=\"Life Sciences & Medicine\", skiprows=10, header=0)\n",
    "\n",
    "    # Drop rows with missing Institution (bottom padding, if any)\n",
    "    df_qs = df_qs.dropna(subset=[\"Institution\"])\n",
    "\n",
    "    # Select top 100 programs\n",
    "    df_top100 = df_qs.head(100)\n",
    "\n",
    "    # Select relevant columns\n",
    "    df_top100 = df_top100[[\n",
    "        \"2025\", \"Institution\", \"Country / Territory\", \"Score\", \"Academic\", \"Employer\", \"Citations\", \"H\", \"IRN\"\n",
    "    ]]\n",
    "\n",
    "    # Rename 2025 column to \"Rank\" for clarity\n",
    "    df_top100 = df_top100.rename(columns={\"2025\": \"Rank\"})\n",
    "    # Clean up the rank column that has = sign prefixed and make it an integer\n",
    "    df_top100['Rank'] = df_top100['Rank'].str.replace('=', '')\n",
    "    df_top100['Rank'] = df_top100['Rank'].astype(int)\n",
    "\n",
    "    # consider only US instituions and rank by H-index (higher the H-index, better the institution) and drop the country column\n",
    "    df_top100_us = df_top100[df_top100['Country / Territory'] == 'United States of America']\n",
    "    df_top100_us = df_top100_us.drop(columns=['Country / Territory'])\n",
    "\n",
    "    # clean up the institution names\n",
    "    list_of_institutions = df_top100_us['Institution'].values.tolist()\n",
    "    cleaned_institutions = []\n",
    "    for institution in list_of_institutions:\n",
    "        cleaned = re.sub(r'\\([^)]*\\)', '', institution)\n",
    "        cleaned = cleaned.replace(',', '-')\n",
    "        cleaned = cleaned.strip()\n",
    "        cleaned_institutions.append(cleaned)\n",
    "\n",
    "    # no space before and after '-' within the string if there are space\n",
    "    cleaned_institutions = [re.sub(r'\\s*-\\s*', '-', institution) for institution in cleaned_institutions]\n",
    "\n",
    "    # remove any duplicates\n",
    "    cleaned_institutions = list(set(cleaned_institutions))\n",
    "\n",
    "    # remove any empty strings\n",
    "    cleaned_institutions = [institution for institution in cleaned_institutions if institution]\n",
    "\n",
    "\n",
    "    return cleaned_institutions, df_top100_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_top_100_us_institutions_for_life_sciences():\n",
    "    top_institutions, df_top100_us = get_top_100_us_institutions_for_life_sciences()\n",
    "    print(top_institutions)\n",
    "\n",
    "test_top_100_us_institutions_for_life_sciences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_admission_data(school_name):\n",
    "    print(f\"Getting admission data for {school_name}\")\n",
    "    base_url = \"https://api.data.gov/ed/collegescorecard/v1/schools\"\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"school.name\": school_name,\n",
    "        \"fields\": \"school.name,latest.admissions.admission_rate.overall,latest.student.demographics.race_ethnicity.asian,latest.student.demographics.race_ethnicity.white,latest.student.demographics.race_ethnicity.hispanic,latest.student.demographics.race_ethnicity.black\",\n",
    "        \"per_page\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    try:\n",
    "        data = response.json()\n",
    "        # Convert to pandas dataframe\n",
    "        df = pd.json_normalize(data['results'])\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"Error getting admission data for {school_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # if df is all NAN, return empty dataframe\n",
    "    if df.isna().all().all():\n",
    "        print(f\"No admission data found for {school_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # check if everything is NaN except the school name column and if so, return empty dataframe \n",
    "    # get all columns except the school name column\n",
    "    columns_to_check = df.columns.tolist()\n",
    "    columns_to_check.remove('school.name')\n",
    "    if df[columns_to_check].isna().all().all():\n",
    "        print(f\"No admission data found for {school_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_institutions, df_top100_us = get_top_100_us_institutions_for_life_sciences()\n",
    "\n",
    "aggregated_df = pd.DataFrame()\n",
    "for institution in top_institutions:\n",
    "    df_admission_data = get_school_admission_data(institution)\n",
    "    if not df_admission_data.empty:\n",
    "        # Initialize aggregated_df with the first non-empty dataframe\n",
    "        if aggregated_df.empty:\n",
    "            aggregated_df = df_admission_data\n",
    "        else:\n",
    "            if not df_admission_data.isna().all().all():\n",
    "                aggregated_df = pd.concat([aggregated_df, df_admission_data], ignore_index=True)\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_institutions_unitid.ipynb\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Imports\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Load Institution List\n",
    "# -------------------------------\n",
    "# Your list of institutions\n",
    "df_my_institutions = pd.read_csv(\"ipeds_institution_list.csv\")\n",
    "my_institution_list = df_my_institutions[\"Institution\"].str.strip().tolist()\n",
    "\n",
    "print(f\"✅ Loaded {len(my_institution_list)} institutions from ipeds_institution_list.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Load IPEDS HD2023.csv\n",
    "# -------------------------------\n",
    "# Download from: https://nces.ed.gov/ipeds/datacenter/DataFiles.aspx → Institutional Characteristics → Header (HD2023.csv)\n",
    "\n",
    "df_hd = pd.read_csv(\"hd2023.csv\", low_memory=False, encoding='latin1')\n",
    "\n",
    "df_hd[\"INSTNM_clean\"] = df_hd[\"INSTNM\"].str.strip().str.lower()\n",
    "\n",
    "#assert('arizona state university' in df_hd[\"INSTNM_clean\"])\n",
    "\n",
    "print(f\"✅ Loaded HD2023.csv with {len(df_hd)} institutions\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Institution Matching\n",
    "# -------------------------------\n",
    "matched_rows = []\n",
    "\n",
    "def find_best_match(inst_clean: str, df_hd: pd.DataFrame) -> tuple[str, float]:\n",
    "    \"\"\"Find best match using prefix matching first, then fuzzy matching.\"\"\"\n",
    "    # Try prefix matching first\n",
    "    prefix_matches = df_hd[df_hd[\"INSTNM_clean\"].str.startswith(inst_clean)]\n",
    "    if not prefix_matches.empty:\n",
    "        return prefix_matches.iloc[0][\"INSTNM_clean\"], 1.0\n",
    "    \n",
    "    # If no prefix match, try fuzzy matching\n",
    "    matches = get_close_matches(inst_clean, df_hd[\"INSTNM_clean\"].tolist(), n=3, cutoff=0.6)\n",
    "    if not matches:\n",
    "        return \"NO MATCH FOUND\", 0.0\n",
    "    \n",
    "    # Get the best match based on word overlap\n",
    "    best_match = None\n",
    "    best_score = 0.0\n",
    "    \n",
    "    for match in matches:\n",
    "        inst_words = set(inst_clean.split())\n",
    "        match_words = set(match.split())\n",
    "        common_words = inst_words.intersection(match_words)\n",
    "        \n",
    "        score = len(common_words) / max(len(inst_words), len(match_words))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = match\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "for inst in my_institution_list:\n",
    "    inst_clean = inst.strip().lower()\n",
    "    best_match, score = find_best_match(inst_clean, df_hd)\n",
    "    \n",
    "    if best_match != \"NO MATCH FOUND\" and score >= 0.5:\n",
    "        unitid = df_hd[df_hd[\"INSTNM_clean\"] == best_match][\"UNITID\"].values[0]\n",
    "        matched_rows.append({\n",
    "            \"Institution\": inst,\n",
    "            \"Matched_Name\": best_match,\n",
    "            \"UNITID\": unitid,\n",
    "            \"Match_Score\": score\n",
    "        })\n",
    "    else:\n",
    "        matched_rows.append({\n",
    "            \"Institution\": inst,\n",
    "            \"Matched_Name\": \"NO MATCH FOUND\",\n",
    "            \"UNITID\": None,\n",
    "            \"Match_Score\": 0.0\n",
    "        })\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ Create DataFrame & Save\n",
    "# -------------------------------\n",
    "df_matches = pd.DataFrame(matched_rows)\n",
    "# make the unitid an integer before saving, output the list for subsequent use\n",
    "df_matches[\"UNITID\"] = df_matches[\"UNITID\"].fillna(-1).astype(int)\n",
    "# remove any rows where the unitid is -1\n",
    "df_matches = df_matches[df_matches[\"UNITID\"] != -1]\n",
    "\n",
    "# output the list for subsequent use\n",
    "unitid_list = df_matches[\"UNITID\"].tolist()\n",
    "print(unitid_list)\n",
    "\n",
    "# Save result\n",
    "df_matches[[\"Institution\", \"UNITID\"]].to_csv(\"institution_unitid_matched.csv\", index=False)\n",
    "\n",
    "# Display summary\n",
    "print(\"✅ Matching complete!\")\n",
    "print(f\"Total institutions: {len(df_matches)}\")\n",
    "print(f\"Matches found: {df_matches['UNITID'].notnull().sum()}\")\n",
    "\n",
    "# Show first 10 matches as preview\n",
    "df_matches.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Get all CSV files from ipeds-all directory\n",
    "ipeds_dir = \"ipeds-all\"\n",
    "csv_files = [f for f in os.listdir(ipeds_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Read and merge all CSV files\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(ipeds_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Standardize column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # Drop duplicate columns before adding to dfs list\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all dataframes on UNITID using reduce with suffixes to handle duplicate columns\n",
    "merged_df = reduce(\n",
    "    lambda left, right: pd.merge(\n",
    "        left, \n",
    "        right, \n",
    "        on='unitid', \n",
    "        how='outer',\n",
    "        suffixes=('', f'_{len(dfs)}')  # Use empty suffix for left, numbered suffix for right\n",
    "    ), \n",
    "    dfs\n",
    ")\n",
    "\n",
    "# Save merged dataframe\n",
    "merged_df.to_csv('iped_data.csv', index=False)\n",
    "\n",
    "print(f\"✅ Successfully merged {len(csv_files)} files into iped_data.csv\")\n",
    "print(f\"Final shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iped_data.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"iped_data.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'institution name_4', 'institution name_4.1', 'institution name_4.2' 'year_4', 'year_4.1', 'year_4.2'\n",
    "df.drop(columns=['institution name_4', 'institution name_4.1', 'institution name_4.2', 'year_4', 'year_4.1', 'year_4.2'], inplace=True)\n",
    "\n",
    "# drop any rows where the unitid is -1\n",
    "df = df[df['unitid'] != -1]\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('iped_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iped_data.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"iped_data_cleaned.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mrc_salary_data.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"mrc_salary_table.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['name', 'state', 'par_mean', 'par_median']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"mrc_salary_table_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>par_mean</th>\n",
       "      <th>par_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASA Institute Of Business &amp; Computer Technology</td>\n",
       "      <td>NY</td>\n",
       "      <td>35390.396804</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>TX</td>\n",
       "      <td>138760.969806</td>\n",
       "      <td>101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>GA</td>\n",
       "      <td>80366.661268</td>\n",
       "      <td>66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academy Of Art University</td>\n",
       "      <td>CA</td>\n",
       "      <td>166594.969612</td>\n",
       "      <td>92300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams State University</td>\n",
       "      <td>CO</td>\n",
       "      <td>76121.816340</td>\n",
       "      <td>67200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Yuba Community College District</td>\n",
       "      <td>CA</td>\n",
       "      <td>61468.370708</td>\n",
       "      <td>48700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Zane State College</td>\n",
       "      <td>OH</td>\n",
       "      <td>65763.334635</td>\n",
       "      <td>53800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Late College Goers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55858.262836</td>\n",
       "      <td>43300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>Never Attended College (up to year 2013)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48010.288464</td>\n",
       "      <td>35200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Colleges with insufficient data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72905.270718</td>\n",
       "      <td>50500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name state       par_mean  \\\n",
       "0     ASA Institute Of Business & Computer Technology    NY   35390.396804   \n",
       "1                        Abilene Christian University    TX  138760.969806   \n",
       "2                Abraham Baldwin Agricultural College    GA   80366.661268   \n",
       "3                           Academy Of Art University    CA  166594.969612   \n",
       "4                              Adams State University    CO   76121.816340   \n",
       "...                                               ...   ...            ...   \n",
       "2197                  Yuba Community College District    CA   61468.370708   \n",
       "2198                               Zane State College    OH   65763.334635   \n",
       "2199                               Late College Goers   NaN   55858.262836   \n",
       "2200         Never Attended College (up to year 2013)   NaN   48010.288464   \n",
       "2201                  Colleges with insufficient data   NaN   72905.270718   \n",
       "\n",
       "      par_median  \n",
       "0          29000  \n",
       "1         101000  \n",
       "2          66000  \n",
       "3          92300  \n",
       "4          67200  \n",
       "...          ...  \n",
       "2197       48700  \n",
       "2198       53800  \n",
       "2199       43300  \n",
       "2200       35200  \n",
       "2201       50500  \n",
       "\n",
       "[2202 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = pd.read_csv(\"mrc_salary_table_cleaned.csv\")\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unitid                                institution  year  tuition_fees  \\\n",
      "0  100663        University of Alabama at Birmingham  2023        8832.0   \n",
      "1  104151  Arizona State University Campus Immersion  2023       12051.0   \n",
      "2  104179                      University of Arizona  2023       13626.0   \n",
      "3  110662       University of California-Los Angeles  2023       13747.0   \n",
      "4  110680         University of California-San Diego  2023       15265.0   \n",
      "\n",
      "   full_time_ug_enrollment  pct_asian  pct_black  pct_hispanic  pct_native  \\\n",
      "0                     9841          8         22             6           0   \n",
      "1                    59707          8          4            23           0   \n",
      "2                    34237          5          4            25           0   \n",
      "3                    32472         27          4            21           0   \n",
      "4                    32852         31          2            22           0   \n",
      "\n",
      "   pct_white  in_state_ug_num  in_state_ug_pct  out_of_state_ug_num  \\\n",
      "0         49           1716.0             82.0                342.0   \n",
      "1         40           8611.0             61.0               4448.0   \n",
      "2         45           4561.0             50.0               4027.0   \n",
      "3         26           5193.0             79.0                873.0   \n",
      "4         19           5556.0             79.0                668.0   \n",
      "\n",
      "   out_of_state_ug_pct  foreign_ug_num  foreign_ug_pct  pct_admitted  yield  \\\n",
      "0                 16.0            37.0             2.0          88.0   22.0   \n",
      "1                 32.0          1034.0             7.0          90.0   23.0   \n",
      "2                 44.0           556.0             6.0          86.0   19.0   \n",
      "3                 13.0           516.0             8.0           9.0   52.0   \n",
      "4                 10.0           777.0            11.0          25.0   22.0   \n",
      "\n",
      "   pct_pell xpgrnt_p  \n",
      "0      41.0        R  \n",
      "1      29.0        R  \n",
      "2      21.0        R  \n",
      "3      26.0        R  \n",
      "4      40.0        R  \n",
      "(71, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"iped_data_cleaned.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataframe shape: (71, 24)\n",
      "\n",
      "First few rows of merged dataframe:\n",
      "   unitid                                institution  year  tuition_fees  \\\n",
      "0  100663        University of Alabama at Birmingham  2023        8832.0   \n",
      "1  104151  Arizona State University Campus Immersion  2023       12051.0   \n",
      "2  104179                      University of Arizona  2023       13626.0   \n",
      "3  110662       University of California-Los Angeles  2023       13747.0   \n",
      "4  110680         University of California-San Diego  2023       15265.0   \n",
      "\n",
      "   full_time_ug_enrollment  pct_asian  pct_black  pct_hispanic  pct_native  \\\n",
      "0                     9841          8         22             6           0   \n",
      "1                    59707          8          4            23           0   \n",
      "2                    34237          5          4            25           0   \n",
      "3                    32472         27          4            21           0   \n",
      "4                    32852         31          2            22           0   \n",
      "\n",
      "   pct_white  ...  foreign_ug_num  foreign_ug_pct  pct_admitted  yield  \\\n",
      "0         49  ...            37.0             2.0          88.0   22.0   \n",
      "1         40  ...          1034.0             7.0          90.0   23.0   \n",
      "2         45  ...           556.0             6.0          86.0   19.0   \n",
      "3         26  ...           516.0             8.0           9.0   52.0   \n",
      "4         19  ...           777.0            11.0          25.0   22.0   \n",
      "\n",
      "   pct_pell  xpgrnt_p                                    name  state  \\\n",
      "0      41.0         R     University Of Alabama At Birmingham     AL   \n",
      "1      29.0         R  California State University, Fullerton     CA   \n",
      "2      21.0         R                    University Of Akron      OH   \n",
      "3      26.0         R   University Of California, Los Angeles     CA   \n",
      "4      40.0         R     University Of California, San Diego     CA   \n",
      "\n",
      "        par_mean par_median  \n",
      "0   92744.637908      74600  \n",
      "1  103739.636215      83300  \n",
      "2   86014.022917      74300  \n",
      "3  171784.801104     105500  \n",
      "4  176468.657437     111300  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge df on institution and df_s on name using maximum prefix match and if it fails on get_closest fuzzy match\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "def get_closest(name, names_list):\n",
    "    \"\"\"Get the closest matching name using fuzzy matching\"\"\"\n",
    "    return max(names_list, key=lambda x: SequenceMatcher(None, name, x).ratio())\n",
    "\n",
    "def get_prefix_match(name, names_list):\n",
    "    \"\"\"Get the longest prefix match from the list of names\"\"\"\n",
    "    matches = [n for n in names_list if name.startswith(n) or n.startswith(name)]\n",
    "    if matches:\n",
    "        return max(matches, key=len)\n",
    "    return None\n",
    "\n",
    "# Create a new column for matched names\n",
    "df['matched_name'] = None\n",
    "\n",
    "# First try prefix matching\n",
    "for idx, row in df.iterrows():\n",
    "    prefix_match = get_prefix_match(row['institution'], df_s['name'].tolist())\n",
    "    if prefix_match:\n",
    "        df.at[idx, 'matched_name'] = prefix_match\n",
    "    else:\n",
    "        # If prefix match fails, use fuzzy matching\n",
    "        closest_match = get_closest(row['institution'], df_s['name'].tolist())\n",
    "        df.at[idx, 'matched_name'] = closest_match\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = pd.merge(df, df_s, left_on='matched_name', right_on='name', how='left')\n",
    "\n",
    "# Drop the temporary matching column\n",
    "merged_df = merged_df.drop('matched_name', axis=1)\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(\"Merged dataframe shape:\", merged_df.shape)\n",
    "print(\"\\nFirst few rows of merged dataframe:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df)\n",
    "merged_df.to_csv(\"proxy_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unitid                                institution  year  tuition_fees  \\\n",
      "0  100663        University of Alabama at Birmingham  2023        8832.0   \n",
      "1  104151  Arizona State University Campus Immersion  2023       12051.0   \n",
      "2  104179                      University of Arizona  2023       13626.0   \n",
      "3  110662       University of California-Los Angeles  2023       13747.0   \n",
      "4  110680         University of California-San Diego  2023       15265.0   \n",
      "\n",
      "   full_time_ug_enrollment  pct_asian  pct_black  pct_hispanic  pct_native  \\\n",
      "0                     9841          8         22             6           0   \n",
      "1                    59707          8          4            23           0   \n",
      "2                    34237          5          4            25           0   \n",
      "3                    32472         27          4            21           0   \n",
      "4                    32852         31          2            22           0   \n",
      "\n",
      "   pct_white  ...  foreign_ug_num  foreign_ug_pct  pct_admitted  yield  \\\n",
      "0         49  ...            37.0             2.0          88.0   22.0   \n",
      "1         40  ...          1034.0             7.0          90.0   23.0   \n",
      "2         45  ...           556.0             6.0          86.0   19.0   \n",
      "3         26  ...           516.0             8.0           9.0   52.0   \n",
      "4         19  ...           777.0            11.0          25.0   22.0   \n",
      "\n",
      "   pct_pell  xpgrnt_p                                    name  state  \\\n",
      "0      41.0         R     University Of Alabama At Birmingham     AL   \n",
      "1      29.0         R  California State University, Fullerton     CA   \n",
      "2      21.0         R                    University Of Akron      OH   \n",
      "3      26.0         R   University Of California, Los Angeles     CA   \n",
      "4      40.0         R     University Of California, San Diego     CA   \n",
      "\n",
      "        par_mean par_median  \n",
      "0   92744.637908      74600  \n",
      "1  103739.636215      83300  \n",
      "2   86014.022917      74300  \n",
      "3  171784.801104     105500  \n",
      "4  176468.657437     111300  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "(71, 24)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"proxy_data.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# print the shape of the dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# print the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unitid', 'institution', 'year', 'tuition_fees',\n",
       "       'full_time_ug_enrollment', 'pct_asian', 'pct_black', 'pct_hispanic',\n",
       "       'pct_native', 'pct_white', 'in_state_ug_num', 'in_state_ug_pct',\n",
       "       'out_of_state_ug_num', 'out_of_state_ug_pct', 'foreign_ug_num',\n",
       "       'foreign_ug_pct', 'pct_admitted', 'yield', 'pct_pell', 'xpgrnt_p',\n",
       "       'name', 'state', 'par_mean', 'par_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
